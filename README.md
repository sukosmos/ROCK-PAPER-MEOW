![image](https://github.com/user-attachments/assets/6da9f9c0-8125-4e0a-9018-20816d5a2871)

# ROCK-PAPER-MEOW ğŸ˜»

Webcamìœ¼ë¡œ ê³ ì–‘ì´ì™€ ê°€ìœ„ë°”ìœ„ë³´ ìŠ¹ë¶€! ğŸ˜¼
<br>
kaggleì˜ ê°€ìœ„ë°”ìœ„ë³´ image datasetì„ í•™ìŠµí•œ MobileNetV2 ê¸°ë°˜ ëª¨ë¸ì´ ëœë¤í•˜ê²Œ íŒ¨ë¥¼ ë‚´ëŠ” ê³ ì–‘ì´ì™€ì˜ ìŠ¹ë¶€ë¥¼ íŒë³„í•©ë‹ˆë‹¤.



<br>

---

## Installation

### 1. Python í™˜ê²½ ì„¤ì •

conda ê°€ìƒí™˜ê²½ì—ì„œ ê°œë°œ

```bash
conda create -n rps_env python=3.9
conda activate rps_env
pip install opencv-python mediapipe pygame tensorflow==2.13.0 numpy
```

<br>


### 2. ëª¨ë¸ & ë°ì´í„°

* `models/rps_mobilenetv2_dropout.keras` â†’ í•™ìŠµëœ ëª¨ë¸ íŒŒì¼
* `assets/images/` â†’ PNG ì´ë¯¸ì§€
* `assets/sound/` â†’ WAV ì‚¬ìš´ë“œ
  * path ì ˆëŒ€ê²½ë¡œë¡œ ìˆ˜ì •í•„ìš”

<br>


### 3. ì‹¤í–‰

```bash
python src/camera_game.py
```

<br>



<br>




## Tech Stack

* Python 3.9
* OpenCV
* MediaPipe
* TensorFlow / Keras
* pygame


<br>



## Dataset

  Kaggleì˜ [ì† ì´ë¯¸ì§€ ë°ì´í„°ì…‹](https://www.kaggle.com/datasets/alexandredj/rock-paper-scissors-dataset)ì„ ì‚¬ìš© (paper, rock, scissorsë¡œ í´ë” ë¶„ë¥˜)
  
  
<br>



## Model Training

* ì‚¬ìš© ëª¨ë¸: MobileNetV2 (Keras ê¸°ë°˜)
* ì…ë ¥ ë°ì´í„°: kaggle ì† ì´ë¯¸ì§€
* í´ë˜ìŠ¤: `paper`, `rock`, `scissors`
* í•™ìŠµ ê²°ê³¼: accuracy ~97% ë‹¬ì„±
    
    ![image](https://github.com/user-attachments/assets/1689d260-91e1-4fbd-893e-17eb765e77c9)

  

ëª¨ë¸ ì €ì¥: `rps_mobilenetv2_dropout.keras`
ëª¨ë¸ ë¡œë“œ: `model_loader.py`

<br>


## OpenCV + MediaPipe

OpenCVë¡œ webcamì˜ ì‹¤ì‹œê°„ frame ìˆ˜ì§‘

MediaPipeë¡œ ì† ì¡´ì¬ ì—¬ë¶€ íŒë‹¨ `detect_hand_presence()`
  ```python
def detect_hand_presence(frame):
    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(image_rgb)
    return results.multi_hand_landmarks is not None
  ```

ëª¨ë¸ ì¶”ë¡  `detect_hand_label`

<br>


- Mediapipeì—ì„œ ì† ìœ„ì¹˜ ì¶”ì¶œ

```python
h, w, _ = frame.shape
landmarks = results.multi_hand_landmarks[0].landmark
x_coords = [lm.x for lm in landmarks]
y_coords = [lm.y for lm in landmarks]
x_min, x_max = int(min(x_coords) * w), int(max(x_coords) * w)
y_min, y_max = int(min(y_coords) * h), int(max(y_coords) * h)
```
- ì´ë¯¸ì§€ ì „ì²˜ë¦¬
  
```python
hand_img = frame[y_min:y_max, x_min:x_max]  # ROI ìë¥´ê¸°
hand_img = cv2.resize(hand_img, (224, 224))  # MobileNetV2 ì…ë ¥ ì‚¬ì´ì¦ˆ
hand_img = hand_img.astype("float32") / 255.0  # ì •ê·œí™”
hand_img = np.expand_dims(hand_img, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
```

- ëª¨ë¸ ì¶”ë¡ 
```python
prediction = model.predict(hand_img)
label = np.argmax(prediction[0])
label_map = {0: "paper", 1: "rock", 2: "scissors"}
return label_map[label]
```

<br>


## FSM 
Finite State machineê¸°ë°˜ìœ¼ë¡œ ê²Œì„ ë¡œì§ì´ êµ¬ì„±ë¨

esc ëˆ„ë¥´ë©´ ì–¸ì œë“ ì§€ ì¢…ë£Œ


![image](https://github.com/user-attachments/assets/5c735923-4e95-42e9-9641-738f55b00c47)

<br>


### MAIN

![image](https://github.com/user-attachments/assets/e9d8eec2-71f6-412d-98d5-c6992659cbd7)


ì´ˆê¸° ìƒíƒœì´ë©° ê²Œì„ ì‹œì‘ í™”ë©´ì„ ë³´ì—¬ì¤Œ

ì‚¬ìš©ìì—ê²Œ "Press SPACE to start" ë©”ì‹œì§€ë¥¼ ë„ì›€

SPACE ì…ë ¥ ì‹œ â†’ `STATE_READY`

<br>


### READY

![image](https://github.com/user-attachments/assets/910e7b43-6ca0-443e-8343-fb3d58a2218f)


ì‚¬ìš©ì ì† ì¡´ì¬ ì—¬ë¶€ í™•ì¸

ì†ì´ ê°ì§€ë˜ë©´ â†’ `STATE_COUNTDOWN`

<br>


### COUNTDOWN

![image](https://github.com/user-attachments/assets/89ad881d-599b-45ea-9187-a51a4f79f655)


3ì´ˆ ë™ì•ˆ ìˆ«ì ì¹´ìš´íŠ¸ í‘œì‹œ (Ready... 3, Ready... 2, Ready... 1)

4ì´ˆ í›„ í”„ë ˆì„ì„ ìº¡ì²˜í•˜ê³  snapshot ì €ì¥

`detect_hand_label()`ì„ í†µí•´ trained modelì´ ì‚¬ìš©ìì˜ ì† ì œìŠ¤ì²˜ ì˜ˆì¸¡ (rock-paper-scissors)

ê³ ì–‘ì´ëŠ” ëœë¤í•œ ì† ëª¨ì–‘ ì„ íƒ

```python
# camera_game.py
 cat_move = random.choice(["rock", "paper", "scissors"])
```

ì´í›„ `STATE_SNAPSHOT`ìœ¼ë¡œ ì´ë™

<br>


### SNAPSHOT

![image](https://github.com/user-attachments/assets/c49a5e65-c06f-4241-8bc2-3dc1161399cb)


ìº¡ì²˜ëœ ì´ë¯¸ì§€ì™€ ê³ ì–‘ì´ ì† ì´ë¯¸ì§€ í‘œì‹œ

ì‚¬ìš©ìì˜ ì† ì œìŠ¤ì²˜ë„ í•¨ê»˜ ë³´ì—¬ì¤Œ

2ì´ˆê°„ ì •ì§€ ìƒíƒœ ìœ ì§€ í›„ â†’ `STATE_RESULT`

<br>


### RESULT

![image](https://github.com/user-attachments/assets/8a7e1b39-f563-453e-8a14-14186b59467d)



ìŠ¹íŒ¨ë¥¼ íŒë‹¨í•˜ê³  ì ìˆ˜ ì—…ë°ì´íŠ¸

ê²°ê³¼ì— ë”°ë¼ win/lose/draw ê³ ì–‘ì´ ì´ë¯¸ì§€ ì¶œë ¥

2ì´ˆ í›„ 

  - ëˆ„êµ°ê°€ 3ì  ë„ë‹¬ ì‹œ â†’ `STATE_GAME_OVER`

  - ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ â†’ `STATE_COUNTDOWN` (ë‹¤ìŒ ë¼ìš´ë“œ)



<br>


### GAMEOVER

![image](https://github.com/user-attachments/assets/c59025d0-39e1-4047-aa45-5a78dedb2ed6)


ê²Œì„ ìµœì¢… ìŠ¹ì ë©”ì‹œì§€ì™€ ì´ë¯¸ì§€ ì¶œë ¥

You win ë˜ëŠ” Cat wins

15ì´ˆ í›„ ì ìˆ˜ ì´ˆê¸°í™”, STATE_MAINìœ¼ë¡œ ëŒì•„ê°

esc ëˆ„ë¥´ë©´ ì¢…ë£Œ



<br>
<br>




## Pygame - sound

OpenCVì— ì‚¬ìš´ë“œë¥¼ ì§€ì›í•˜ê¸° ìœ„í•´ Pygame ì‚¬ìš©

ìŒì•… ì¬ìƒ ì£¼ê¸°ê°€ ì§§ìœ¼ë¯€ë¡œ `pre_load()`ì™€ cache ì‚¬ìš©ìœ¼ë¡œ íš¨ìœ¨ì  ìì› ê´€ë¦¬


<br>

<br>




## Demo Video

https://www.youtube.com/watch?v=Ml9RkVhMupY


<br>


<br>



## Issue
https://github.com/sukosmos/Rock-Paper-Scissors-with-cat/issues?q=is%3Aissue%20state%3Aclosed



<br>


<br>


# í•œê³„ ë° ê°œì„ ì‚¬í•­ 
## ëª¨ë¸ ì„±ëŠ¥

- ëª¨ë¸ì´ í™”ë©´ìƒ ì˜¤ë¥¸ìª½ ì†ì˜ ì¸ì‹ ì„±ëŠ¥ì´ ë” ìš°ìˆ˜í•¨. webcamì€ ì¢Œìš°ë°˜ì „ì´ ì ìš©ë˜ë¯€ë¡œ ì™¼ì† ì‚¬ìš©ì‹œ íŒë‹¨ ì„±ëŠ¥ì´ ë›°ì–´ë‚¨
- ë°°ê²½ì´ ë³µì¡í•  ì‹œ ì„±ëŠ¥ ëŒ€í­ ì €í•˜, ì†ì´ ì˜ ë³´ì´ë„ë¡ ë°°ê²½ì„ ì„¤ì •í•´ì•¼í•¨
- ë” ì¢‹ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆëŠ” training ë°©ë²• ì°¾ì•„ë³´ê¸°

## gamelogic - state=COUNTDOWN
- ê°€ìœ„ë°”ìœ„ë³´ ì¹´ìš´íŠ¸ì— ì†ì„ ë‚´ë©´ ì¸ì‹ì´ ëŠë¦° issue ë°œìƒ
- `if elapsed >= 3.5:` ì—ì„œ `if elapsed >= 4:`ë¡œ ì‹œê°„ ì¡°ì •
- ê°œì„  ì™„ë£Œ

## audio_player

- state=readyì¼ ë•Œ ì†Œë¦¬ê°€ ì•ˆ ë‚˜ëŠ” ì˜¤ë¥˜ê°€ ìˆìŒ
- audio playê°€ ë§ì„ìˆ˜ë¡ ì¬ìƒ ì§€ì—° ë°œìƒ

## UX

- ë” ê¹”ë”í•œ UX ë””ìì¸ í•„ìš”

## ì ìš©ì„±

- í˜„ì¬ python OpenCV í™˜ê²½ì—ì„œë§Œ ì‚¬ìš©ê°€ëŠ¥
- ì›¹/ì•± ë“±ì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ê°œë°œ 



<br><br>

---

# ì°¸ê³ 

- Kaggle Rock-Paper-Scissors-Dataset: https://www.kaggle.com/datasets/alexandredj/rock-paper-scissors-dataset
- MobileNet: https://arxiv.org/abs/1801.04381
- MediaPipe-hands: https://github.com/google-ai-edge/mediapipe/blob/master/docs/solutions/hands.md
- ChatGPT

<br><br>

